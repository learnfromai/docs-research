# Dependency Scanning: Third-Party Vulnerability Management

## üéØ Overview

Dependency scanning identifies security vulnerabilities in third-party libraries, frameworks, and components used by your application. With modern applications using hundreds of dependencies, this represents a critical attack surface that requires continuous monitoring and management.

## üì¶ Dependency Security Fundamentals

### The Dependency Challenge

**Modern Dependency Landscape:**
- Average web application uses **400-1,200** dependencies
- **78%** of codebases contain at least one vulnerability
- **84%** of breaches involve vulnerabilities in dependencies
- Average time to fix: **49 days** for critical vulnerabilities
- **650%** increase in supply chain attacks (2021-2022)

**Types of Dependency Vulnerabilities:**
1. **Known CVEs**: Publicly disclosed vulnerabilities
2. **Zero-day Exploits**: Unknown vulnerabilities being exploited
3. **Malicious Packages**: Intentionally harmful code
4. **License Violations**: Legal compliance issues
5. **Outdated Dependencies**: Missing security patches

### Supply Chain Attack Vectors

**Common Attack Methods:**
- **Typosquatting**: Malicious packages with similar names
- **Dependency Confusion**: Internal vs external package conflicts
- **Compromised Maintainer Accounts**: Legitimate packages modified
- **Build Process Injection**: CI/CD pipeline compromises
- **Transitive Dependencies**: Vulnerabilities in sub-dependencies

## üèÜ Leading Dependency Scanning Tools

### 1. GitHub Dependabot - Native Integration

#### Advanced Configuration

**Enterprise Dependabot Setup:**
```yaml
# .github/dependabot.yml
version: 2
updates:
  # JavaScript/Node.js dependencies
  - package-ecosystem: "npm"
    directory: "/"
    schedule:
      interval: "daily"
      time: "02:00"
      timezone: "Asia/Manila"
    
    # Advanced grouping for easier review
    groups:
      security-updates:
        patterns:
          - "*"
        update-types:
          - "security-update"
        priority: 10
      
      production-dependencies:
        patterns:
          - "react*"
          - "next*"
          - "express*"
          - "@types/*"
        update-types:
          - "minor"
          - "patch"
        priority: 8
      
      development-dependencies:
        patterns:
          - "eslint*"
          - "jest*"
          - "@testing-library/*"
          - "webpack*"
        update-types:
          - "minor"
          - "patch"
        priority: 5
    
    # Custom commit messages
    commit-message:
      prefix: "deps"
      prefix-development: "deps-dev"
      include: "scope"
    
    # Reviewer assignment based on dependency type
    reviewers:
      - "security-team"  # Always review security updates
    assignees:
      - "tech-lead"
    
    # Ignore specific updates
    ignore:
      - dependency-name: "react"
        versions: ["18.0.0"]
        reason: "Breaking changes not compatible with current setup"
      
      - dependency-name: "lodash"
        versions: [">= 4.17.0, < 4.18.0"]
        reason: "Known performance issues in this version range"
    
    # Advanced configuration
    open-pull-requests-limit: 20
    rebase-strategy: "auto"
    
    # Allow Dependabot to resolve conflicts
    allow:
      - dependency-type: "direct"
        update-type: "version-update:semver-patch"
      - dependency-type: "direct"
        update-type: "version-update:semver-minor"
      - dependency-type: "indirect"
        update-type: "security-update"

  # Docker dependencies
  - package-ecosystem: "docker"
    directory: "/docker"
    schedule:
      interval: "weekly"
      day: "monday"
    reviewers:
      - "devops-team"
    
  # GitHub Actions
  - package-ecosystem: "github-actions"
    directory: "/"
    schedule:
      interval: "monthly"
    commit-message:
      prefix: "ci"
      include: "scope"

  # Python dependencies (if using Python services)
  - package-ecosystem: "pip"
    directory: "/python-services"
    schedule:
      interval: "weekly"
    groups:
      django-dependencies:
        patterns:
          - "django*"
          - "djangorestframework*"
        update-types:
          - "minor"
          - "patch"
```

**Automated Dependabot Workflow:**
```yaml
# .github/workflows/dependabot-auto-merge.yml
name: Dependabot Auto-merge

on:
  pull_request:
    types: [opened, synchronize]

jobs:
  auto-merge:
    if: github.actor == 'dependabot[bot]'
    runs-on: ubuntu-latest
    permissions:
      contents: write
      pull-requests: write
      
    steps:
    - name: Check if PR is from Dependabot
      id: dependabot-check
      run: |
        if [[ "${{ github.actor }}" == "dependabot[bot]" ]]; then
          echo "is_dependabot=true" >> $GITHUB_OUTPUT
        else
          echo "is_dependabot=false" >> $GITHUB_OUTPUT
        fi
    
    - name: Get PR details
      if: steps.dependabot-check.outputs.is_dependabot == 'true'
      id: pr-details
      uses: actions/github-script@v7
      with:
        script: |
          const pr = context.payload.pull_request;
          const title = pr.title.toLowerCase();
          
          // Determine update type
          let updateType = 'unknown';
          let autoMerge = false;
          
          if (title.includes('security')) {
            updateType = 'security';
            autoMerge = true; // Always auto-merge security updates
          } else if (title.includes('patch')) {
            updateType = 'patch';
            autoMerge = true; // Auto-merge patch updates
          } else if (title.includes('minor')) {
            updateType = 'minor';
            // Only auto-merge minor updates for dev dependencies
            autoMerge = title.includes('deps-dev');
          } else if (title.includes('major')) {
            updateType = 'major';
            autoMerge = false; // Never auto-merge major updates
          }
          
          return {
            updateType,
            autoMerge,
            title: pr.title,
            body: pr.body
          };
    
    - name: Run security checks
      if: fromJSON(steps.pr-details.outputs.result).autoMerge == true
      run: |
        # Install dependencies and run security audit
        npm ci
        npm audit --audit-level=moderate
        
        # Run tests to ensure nothing breaks
        npm test
        
        # Run type checking
        npm run type-check
    
    - name: Auto-merge if safe
      if: fromJSON(steps.pr-details.outputs.result).autoMerge == true
      uses: actions/github-script@v7
      with:
        script: |
          const prDetails = ${{ steps.pr-details.outputs.result }};
          
          // Add approval
          await github.rest.pulls.createReview({
            owner: context.repo.owner,
            repo: context.repo.repo,
            pull_number: context.payload.pull_request.number,
            event: 'APPROVE',
            body: `Auto-approving ${prDetails.updateType} update after successful security checks.`
          });
          
          // Enable auto-merge
          await github.rest.pulls.merge({
            owner: context.repo.owner,
            repo: context.repo.repo,
            pull_number: context.payload.pull_request.number,
            commit_title: `Auto-merge: ${prDetails.title}`,
            commit_message: 'Automatically merged after security validation',
            merge_method: 'squash'
          });
    
    - name: Notify team of manual review needed
      if: fromJSON(steps.pr-details.outputs.result).autoMerge == false
      uses: actions/github-script@v7
      with:
        script: |
          const prDetails = ${{ steps.pr-details.outputs.result }};
          
          await github.rest.issues.createComment({
            owner: context.repo.owner,
            repo: context.repo.repo,
            issue_number: context.payload.pull_request.number,
            body: `üîç **Manual Review Required**
            
            This ${prDetails.updateType} update requires manual review before merging.
            
            **Checklist:**
            - [ ] Review breaking changes
            - [ ] Test critical user flows
            - [ ] Check for API changes
            - [ ] Verify backward compatibility
            
            cc: @security-team @tech-lead`
          });
```

### 2. Snyk - Comprehensive Vulnerability Management

#### Advanced Integration

**Enterprise Snyk Configuration:**
```yaml
# .snyk
version: v1.25.0

# Language-specific settings
language-settings:
  javascript:
    # Include dev dependencies in scanning
    dev: true
    # Ignore missing package-lock.json warnings
    ignore-missing-files: true
    
  python:
    # Ignore specific Python versions
    ignore-python-version: false
    
  docker:
    # Dockerfile analysis settings
    dockerfile-analysis: true

# Ignore specific vulnerabilities with justification
ignore:
  # High severity but no exploit available for our use case
  'SNYK-JS-LODASH-567746':
    - '*':
        reason: 'Prototype pollution not exploitable in our server-side context'
        expires: '2024-12-31T23:59:59.999Z'
        created: '2024-01-15T10:30:00.000Z'
        reviewer: 'security-team@edtech.com'
  
  # Medium severity - mitigated by input validation
  'SNYK-JS-VALIDATOR-174880':
    - 'src/utils/validation.js':
        reason: 'Input is pre-validated and sanitized before reaching this function'
        expires: '2024-06-30T23:59:59.999Z'
        created: '2024-01-15T10:30:00.000Z'
        reviewer: 'lead-developer@edtech.com'

# Patch vulnerabilities
patch:
  # Apply Snyk patches for specific vulnerabilities
  'SNYK-JS-MINIMIST-559764':
    - minimist:
        patched: '2024-01-15T10:30:00.000Z'

# Organization-specific policies
policies:
  # Fail build on high/critical vulnerabilities
  'high-severity-fail': true
  'critical-severity-fail': true
  
  # License policies
  license-policy:
    # Allowed licenses
    allowedLicenses:
      - 'MIT'
      - 'Apache-2.0'
      - 'BSD-3-Clause'
      - 'ISC'
    
    # Disallowed licenses
    disallowedLicenses:
      - 'GPL-3.0'
      - 'AGPL-3.0'
      - 'CPAL-1.0'
    
    # Require manual review for these licenses
    reviewRequired:
      - 'LGPL-2.1'
      - 'MPL-2.0'
      - 'EPL-2.0'
```

**Advanced CI/CD Integration:**
```yaml
# .github/workflows/snyk-security.yml
name: Snyk Security Scan

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]
  schedule:
    - cron: '0 2 * * *'  # Daily at 2 AM

jobs:
  snyk-test:
    runs-on: ubuntu-latest
    permissions:
      security-events: write
      
    steps:
    - uses: actions/checkout@v4
    
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'
        cache: 'npm'
    
    - name: Install dependencies
      run: npm ci
    
    - name: Run Snyk to check for vulnerabilities
      uses: snyk/actions/node@master
      env:
        SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}
      with:
        args: >
          --severity-threshold=high 
          --fail-on=upgradable 
          --file=package.json
          --policy-path=.snyk
          --json
          --sarif-file-output=snyk-results.sarif
    
    - name: Upload Snyk results to GitHub Code Scanning
      uses: github/codeql-action/upload-sarif@v3
      with:
        sarif_file: snyk-results.sarif
      if: always()
    
    - name: Run Snyk to check Docker images
      if: github.event_name == 'push'
      uses: snyk/actions/docker@master
      env:
        SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}
      with:
        image: edtech-platform:latest
        args: --severity-threshold=high --file=Dockerfile
    
    - name: Generate detailed report
      if: always()
      run: |
        # Generate comprehensive Snyk report
        snyk test --json > snyk-detailed-report.json
        
        # Create summary
        python scripts/process-snyk-results.py \
          --input snyk-detailed-report.json \
          --output snyk-summary.md
    
    - name: Upload artifacts
      uses: actions/upload-artifact@v4
      with:
        name: snyk-security-reports
        path: |
          snyk-detailed-report.json
          snyk-summary.md
          snyk-results.sarif
        retention-days: 30

  license-compliance:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    
    - name: Check license compliance
      uses: snyk/actions/node@master
      env:
        SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}
      with:
        command: test
        args: --print-deps --json
    
    - name: Generate license report
      run: |
        # Generate license compliance report
        snyk test --print-deps --json | \
        jq '.dependencies | to_entries[] | {name: .key, licenses: .value.licenses}' > \
        license-report.json
        
        # Check for license violations
        python scripts/check-license-compliance.py \
          --input license-report.json \
          --policy .snyk
```

**Custom Snyk Processing Script:**
```python
# scripts/process-snyk-results.py
import json
import argparse
from datetime import datetime
from typing import Dict, List

class SnykResultsProcessor:
    def __init__(self, input_file: str):
        with open(input_file, 'r') as f:
            self.results = json.load(f)
    
    def generate_summary(self) -> Dict:
        """Generate vulnerability summary"""
        summary = {
            'total_vulnerabilities': 0,
            'by_severity': {'critical': 0, 'high': 0, 'medium': 0, 'low': 0},
            'by_type': {},
            'upgradeable': 0,
            'patchable': 0,
            'unique_vulnerabilities': set()
        }
        
        for vulnerability in self.results.get('vulnerabilities', []):
            summary['total_vulnerabilities'] += 1
            
            # Count by severity
            severity = vulnerability.get('severity', 'unknown')
            summary['by_severity'][severity] = summary['by_severity'].get(severity, 0) + 1
            
            # Count by vulnerability type
            vuln_type = vulnerability.get('type', 'unknown')
            summary['by_type'][vuln_type] = summary['by_type'].get(vuln_type, 0) + 1
            
            # Check if upgradeable or patchable
            if vulnerability.get('isUpgradable'):
                summary['upgradeable'] += 1
            if vulnerability.get('isPatchable'):
                summary['patchable'] += 1
            
            # Track unique vulnerabilities
            vuln_id = vulnerability.get('id')
            if vuln_id:
                summary['unique_vulnerabilities'].add(vuln_id)
        
        summary['unique_count'] = len(summary['unique_vulnerabilities'])
        return summary
    
    def get_critical_vulnerabilities(self) -> List[Dict]:
        """Get critical and high severity vulnerabilities"""
        critical_vulns = []
        
        for vuln in self.results.get('vulnerabilities', []):
            if vuln.get('severity') in ['critical', 'high']:
                critical_vulns.append({
                    'id': vuln.get('id'),
                    'title': vuln.get('title'),
                    'severity': vuln.get('severity'),
                    'package': vuln.get('packageName'),
                    'version': vuln.get('version'),
                    'upgrade_path': vuln.get('upgradePath'),
                    'cve': vuln.get('identifiers', {}).get('CVE', []),
                    'cwe': vuln.get('identifiers', {}).get('CWE', []),
                    'cvss_score': vuln.get('cvssScore'),
                    'published': vuln.get('publicationTime'),
                    'disclosure': vuln.get('disclosureTime')
                })
        
        return sorted(critical_vulns, key=lambda x: x['cvss_score'] or 0, reverse=True)
    
    def generate_markdown_report(self) -> str:
        """Generate markdown report"""
        summary = self.generate_summary()
        critical_vulns = self.get_critical_vulnerabilities()
        
        report = f"""# Snyk Security Scan Report

**Generated**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## Summary

- **Total Vulnerabilities**: {summary['total_vulnerabilities']}
- **Unique Vulnerabilities**: {summary['unique_count']}
- **Upgradeable**: {summary['upgradeable']}
- **Patchable**: {summary['patchable']}

### By Severity
- üî¥ **Critical**: {summary['by_severity'].get('critical', 0)}
- üü† **High**: {summary['by_severity'].get('high', 0)}
- üü° **Medium**: {summary['by_severity'].get('medium', 0)}
- üü¢ **Low**: {summary['by_severity'].get('low', 0)}

## Critical & High Severity Vulnerabilities

"""
        
        for vuln in critical_vulns[:10]:  # Top 10 critical
            severity_emoji = 'üî¥' if vuln['severity'] == 'critical' else 'üü†'
            
            report += f"""### {severity_emoji} {vuln['title']}

- **Package**: {vuln['package']} v{vuln['version']}
- **Severity**: {vuln['severity'].upper()} (CVSS: {vuln['cvss_score']})
- **CVE**: {', '.join(vuln['cve']) if vuln['cve'] else 'N/A'}
- **CWE**: {', '.join(vuln['cwe']) if vuln['cwe'] else 'N/A'}
- **Upgrade Path**: {' ‚Üí '.join(vuln['upgrade_path']) if vuln['upgrade_path'] else 'No upgrade available'}
- **Published**: {vuln['published'][:10] if vuln['published'] else 'Unknown'}

"""
        
        # Add remediation recommendations
        report += f"""
## Remediation Recommendations

### Immediate Actions (Critical & High)
"""
        
        upgrade_count = len([v for v in critical_vulns if v['upgrade_path']])
        no_upgrade_count = len(critical_vulns) - upgrade_count
        
        if upgrade_count > 0:
            report += f"- **Upgrade {upgrade_count} packages** to secure versions\n"
        
        if no_upgrade_count > 0:
            report += f"- **{no_upgrade_count} vulnerabilities** have no available upgrades - consider alternative packages\n"
        
        report += f"""
### Commands to Fix Upgradeable Issues
```bash
# Update packages with available fixes
npm update

# For specific critical packages
"""
        
        for vuln in critical_vulns[:5]:  # Top 5 with upgrade paths
            if vuln['upgrade_path']:
                target_version = vuln['upgrade_path'][-1] if vuln['upgrade_path'] else None
                if target_version:
                    report += f"npm install {vuln['package']}@{target_version}\n"
        
        report += "```\n"
        
        return report

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Process Snyk scan results')
    parser.add_argument('--input', required=True, help='Input JSON file from Snyk')
    parser.add_argument('--output', required=True, help='Output markdown file')
    
    args = parser.parse_args()
    
    processor = SnykResultsProcessor(args.input)
    report = processor.generate_markdown_report()
    
    with open(args.output, 'w') as f:
        f.write(report)
    
    print(f"Report generated: {args.output}")
```

### 3. OWASP Dependency Check - Free Alternative

#### Advanced Configuration

**Comprehensive Dependency Check Setup:**
```xml
<!-- dependency-check-config.xml -->
<dependency-check>
    <database>
        <!-- Use local database for faster scans -->
        <connectionString>jdbc:h2:file:./dependency-check-data/odc</connectionString>
        
        <!-- Auto-update database -->
        <autoUpdate>true</autoUpdate>
        
        <!-- Update timeout (30 minutes) -->
        <updateTimeout>30</updateTimeout>
    </database>
    
    <scanners>
        <!-- Enable all scanners -->
        <archive>true</archive>
        <jar>true</jar>
        <node>true</node>
        <nodeAudit>true</nodeAudit>
        <yarn>true</yarn>
        <pnpm>true</pnpm>
        <python>true</python>
        <pypi>true</pypi>
        <docker>true</docker>
        
        <!-- Disable unnecessary scanners for performance -->
        <assembly>false</assembly>
        <msbuild>false</msbuild>
        <nuget>false</nuget>
    </scanners>
    
    <suppressions>
        <!-- Suppression file location -->
        <file>dependency-check-suppressions.xml</file>
    </suppressions>
    
    <reporting>
        <!-- Output formats -->
        <formats>
            <format>HTML</format>
            <format>JSON</format>
            <format>SARIF</format>
            <format>XML</format>
        </formats>
        
        <!-- Custom report title -->
        <title>EdTech Platform Dependency Security Report</title>
    </reporting>
    
    <analysis>
        <!-- Fail build on CVSS 7+ -->
        <failBuildOnCVSS>7.0</failBuildOnCVSS>
        
        <!-- Skip test dependencies -->
        <skipTestScope>true</skipTestScope>
        
        <!-- Enable experimental analyzers -->
        <experimental>true</experimental>
    </analysis>
</dependency-check>
```

**GitHub Actions Integration:**
```yaml
# .github/workflows/owasp-dependency-check.yml
name: OWASP Dependency Check

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]
  schedule:
    - cron: '0 3 * * 0'  # Weekly on Sunday at 3 AM

jobs:
  dependency-check:
    runs-on: ubuntu-latest
    permissions:
      security-events: write
      
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Setup Java for Dependency Check
      uses: actions/setup-java@v4
      with:
        java-version: '11'
        distribution: 'temurin'
    
    - name: Cache Dependency Check database
      uses: actions/cache@v4
      with:
        path: ~/.dependency-check
        key: dependency-check-db-${{ github.run_id }}
        restore-keys: |
          dependency-check-db-
    
    - name: Run OWASP Dependency Check
      uses: dependency-check/Dependency-Check_Action@main
      with:
        project: 'EdTech Platform'
        path: '.'
        format: 'ALL'
        args: >
          --enableRetired
          --enableExperimental
          --nodePackageSkipDevDependencies false
          --nodeAuditSkipDevDependencies false
          --failOnCVSS 7
          --suppression dependency-check-suppressions.xml
    
    - name: Upload SARIF results
      uses: github/codeql-action/upload-sarif@v3
      with:
        sarif_file: reports/dependency-check-report.sarif
      if: always()
    
    - name: Process results and create summary
      if: always()
      run: |
        # Convert JSON report to markdown summary
        python scripts/process-dependency-check-results.py \
          --input reports/dependency-check-report.json \
          --output dependency-check-summary.md
    
    - name: Upload reports
      uses: actions/upload-artifact@v4
      with:
        name: dependency-check-reports
        path: |
          reports/
          dependency-check-summary.md
        retention-days: 30
    
    - name: Comment on PR
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          
          if (fs.existsSync('dependency-check-summary.md')) {
            const summary = fs.readFileSync('dependency-check-summary.md', 'utf8');
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: `## üîç OWASP Dependency Check Results\n\n${summary}`
            });
          }
```

## üîí Advanced Dependency Security Strategies

### 1. Supply Chain Attack Prevention

**Package Integrity Verification:**
```javascript
// scripts/verify-package-integrity.js
const crypto = require('crypto');
const fs = require('fs');
const path = require('path');
const { execSync } = require('child_process');

class PackageIntegrityVerifier {
    constructor() {
        this.packageLock = this.loadPackageLock();
        this.knownMaliciousPatterns = this.loadMaliciousPatterns();
    }
    
    loadPackageLock() {
        try {
            return JSON.parse(fs.readFileSync('package-lock.json', 'utf8'));
        } catch (error) {
            throw new Error('Could not load package-lock.json');
        }
    }
    
    loadMaliciousPatterns() {
        return [
            // Cryptocurrency mining patterns
            /bitcoin|crypto.*mining|cryptonight/i,
            // Command execution patterns
            /child_process\.exec|eval\(|Function\(/i,
            // Network communication patterns
            /http\.request|net\.connect|\.send\(/i,
            // File system access patterns
            /fs\.writeFile|fs\.unlink|rimraf/i,
            // Environment variable access
            /process\.env|\.env/i
        ];
    }
    
    async verifyAllPackages() {
        const results = {
            verified: 0,
            failed: 0,
            suspicious: 0,
            details: []
        };
        
        const packages = this.packageLock.packages || {};
        
        for (const [packagePath, packageInfo] of Object.entries(packages)) {
            if (packagePath === '') continue; // Skip root package
            
            const result = await this.verifyPackage(packagePath, packageInfo);
            results.details.push(result);
            
            switch (result.status) {
                case 'verified':
                    results.verified++;
                    break;
                case 'failed':
                    results.failed++;
                    break;
                case 'suspicious':
                    results.suspicious++;
                    break;
            }
        }
        
        return results;
    }
    
    async verifyPackage(packagePath, packageInfo) {
        const packageName = packagePath.replace('node_modules/', '');
        
        try {
            // Check integrity hash if available
            const integrityCheck = this.verifyIntegrity(packagePath, packageInfo);
            
            // Check for suspicious code patterns
            const suspiciousCheck = await this.checkForSuspiciousCode(packagePath);
            
            // Check package metadata
            const metadataCheck = this.checkPackageMetadata(packageName, packageInfo);
            
            return {
                package: packageName,
                status: this.determineStatus(integrityCheck, suspiciousCheck, metadataCheck),
                checks: {
                    integrity: integrityCheck,
                    suspicious_code: suspiciousCheck,
                    metadata: metadataCheck
                }
            };
        } catch (error) {
            return {
                package: packageName,
                status: 'failed',
                error: error.message
            };
        }
    }
    
    verifyIntegrity(packagePath, packageInfo) {
        if (!packageInfo.integrity) {
            return { status: 'no_hash', message: 'No integrity hash available' };
        }
        
        try {
            // This is a simplified check - in practice, you'd verify against actual files
            const expectedHash = packageInfo.integrity;
            // const actualHash = this.calculatePackageHash(packagePath);
            
            return { status: 'verified', hash: expectedHash };
        } catch (error) {
            return { status: 'failed', error: error.message };
        }
    }
    
    async checkForSuspiciousCode(packagePath) {
        const suspiciousFindings = [];
        
        try {
            const packageDir = path.join('node_modules', packagePath.replace('node_modules/', ''));
            
            if (!fs.existsSync(packageDir)) {
                return { status: 'not_found', findings: [] };
            }
            
            // Read main files and check for suspicious patterns
            const mainFiles = ['index.js', 'main.js', 'lib/index.js'];
            
            for (const file of mainFiles) {
                const filePath = path.join(packageDir, file);
                
                if (fs.existsSync(filePath)) {
                    const content = fs.readFileSync(filePath, 'utf8');
                    
                    for (const pattern of this.knownMaliciousPatterns) {
                        if (pattern.test(content)) {
                            suspiciousFindings.push({
                                file: filePath,
                                pattern: pattern.toString(),
                                match: content.match(pattern)?.[0]
                            });
                        }
                    }
                }
            }
            
            return {
                status: suspiciousFindings.length > 0 ? 'suspicious' : 'clean',
                findings: suspiciousFindings
            };
        } catch (error) {
            return { status: 'error', error: error.message };
        }
    }
    
    checkPackageMetadata(packageName, packageInfo) {
        const checks = [];
        
        // Check for typosquatting
        const suspiciousNames = [
            'lodaash', 'reqeust', 'expres', 'reacct', 'axios-http'
        ];
        
        if (suspiciousNames.some(name => packageName.includes(name))) {
            checks.push({
                type: 'typosquatting',
                severity: 'high',
                message: 'Package name resembles popular package but with typos'
            });
        }
        
        // Check version patterns
        if (packageInfo.version && packageInfo.version.includes('rc') && 
            !packageInfo.version.includes('beta') && !packageInfo.version.includes('alpha')) {
            checks.push({
                type: 'suspicious_version',
                severity: 'medium',
                message: 'Unusual version pattern detected'
            });
        }
        
        // Check for recently published packages with high version numbers
        const versionParts = packageInfo.version?.split('.') || [];
        if (versionParts[0] && parseInt(versionParts[0]) > 100) {
            checks.push({
                type: 'version_inflation',
                severity: 'medium',
                message: 'Suspiciously high major version number'
            });
        }
        
        return {
            status: checks.length > 0 ? 'suspicious' : 'clean',
            checks: checks
        };
    }
    
    determineStatus(integrityCheck, suspiciousCheck, metadataCheck) {
        if (suspiciousCheck.status === 'suspicious' || 
            metadataCheck.checks.some(c => c.severity === 'high')) {
            return 'suspicious';
        }
        
        if (integrityCheck.status === 'failed' || suspiciousCheck.status === 'error') {
            return 'failed';
        }
        
        return 'verified';
    }
    
    generateReport(results) {
        const report = `# Package Integrity Verification Report

**Generated**: ${new Date().toISOString()}

## Summary
- ‚úÖ **Verified**: ${results.verified} packages
- ‚ùå **Failed**: ${results.failed} packages  
- ‚ö†Ô∏è **Suspicious**: ${results.suspicious} packages
- **Total**: ${results.details.length} packages

## Suspicious Packages
${results.details
    .filter(p => p.status === 'suspicious')
    .map(p => `### ${p.package}
${p.checks.suspicious_code.findings.map(f => `- **${f.pattern}**: ${f.match}`).join('\n')}
${p.checks.metadata.checks.map(c => `- **${c.type}**: ${c.message}`).join('\n')}
`).join('\n')}

## Failed Verifications
${results.details
    .filter(p => p.status === 'failed')
    .map(p => `- **${p.package}**: ${p.error || 'Verification failed'}`).join('\n')}

## Recommendations
${results.suspicious > 0 ? 'üö® **URGENT**: Review suspicious packages before production deployment' : ''}
${results.failed > 0 ? '‚ö†Ô∏è **WARNING**: Investigate failed package verifications' : ''}
${results.suspicious === 0 && results.failed === 0 ? '‚úÖ **CLEAN**: All packages passed integrity verification' : ''}
`;
        
        return report;
    }
}

// Usage
async function main() {
    const verifier = new PackageIntegrityVerifier();
    const results = await verifier.verifyAllPackages();
    const report = verifier.generateReport(results);
    
    fs.writeFileSync('package-integrity-report.md', report);
    console.log('Package integrity report generated');
    
    // Exit with error code if suspicious packages found
    if (results.suspicious > 0 || results.failed > 0) {
        process.exit(1);
    }
}

if (require.main === module) {
    main().catch(console.error);
}

module.exports = PackageIntegrityVerifier;
```

### 2. Automated Dependency Updates

**Smart Update Strategy:**
```javascript
// scripts/smart-dependency-updater.js
const { execSync } = require('child_process');
const fs = require('fs');
const semver = require('semver');

class SmartDependencyUpdater {
    constructor() {
        this.packageJson = JSON.parse(fs.readFileSync('package.json', 'utf8'));
        this.updateStrategy = this.loadUpdateStrategy();
    }
    
    loadUpdateStrategy() {
        return {
            // Critical security updates - always update immediately
            security: {
                auto_update: true,
                max_delay_hours: 4,
                require_tests: true
            },
            
            // Production dependencies - careful updates
            production: {
                auto_update: false,
                update_types: ['patch'], // Only patch updates
                require_manual_review: ['major', 'minor'],
                testing_required: true,
                staging_deployment_required: true
            },
            
            // Development dependencies - more lenient
            development: {
                auto_update: true,
                update_types: ['patch', 'minor'],
                require_manual_review: ['major'],
                testing_required: false
            },
            
            // Framework updates - special handling
            frameworks: {
                packages: ['react', 'next', 'express', 'typescript'],
                auto_update: false,
                require_impact_assessment: true,
                require_team_review: true
            }
        };
    }
    
    async analyzeUpdates() {
        const outdated = this.getOutdatedPackages();
        const updatePlan = [];
        
        for (const pkg of outdated) {
            const analysis = await this.analyzePackageUpdate(pkg);
            updatePlan.push(analysis);
        }
        
        return this.prioritizeUpdates(updatePlan);
    }
    
    getOutdatedPackages() {
        try {
            const result = execSync('npm outdated --json', { encoding: 'utf8' });
            return Object.entries(JSON.parse(result)).map(([name, info]) => ({
                name,
                current: info.current,
                wanted: info.wanted,
                latest: info.latest,
                type: this.packageJson.dependencies[name] ? 'production' : 'development'
            }));
        } catch (error) {
            // npm outdated returns non-zero exit code when packages are outdated
            const output = error.stdout || error.message;
            try {
                return Object.entries(JSON.parse(output)).map(([name, info]) => ({
                    name,
                    current: info.current,
                    wanted: info.wanted,
                    latest: info.latest,
                    type: this.packageJson.dependencies[name] ? 'production' : 'development'
                }));
            } catch {
                return [];
            }
        }
    }
    
    async analyzePackageUpdate(pkg) {
        const analysis = {
            package: pkg.name,
            current_version: pkg.current,
            target_version: pkg.latest,
            update_type: this.getUpdateType(pkg.current, pkg.latest),
            dependency_type: pkg.type,
            security_update: false,
            breaking_changes: false,
            recommendation: 'review',
            risk_level: 'medium',
            auto_update: false
        };
        
        // Check for security vulnerabilities
        analysis.security_update = await this.isSecurityUpdate(pkg.name, pkg.current, pkg.latest);
        
        // Check for breaking changes
        analysis.breaking_changes = await this.hasBreakingChanges(pkg.name, pkg.current, pkg.latest);
        
        // Determine update strategy
        analysis.recommendation = this.getUpdateRecommendation(analysis);
        analysis.risk_level = this.assessRiskLevel(analysis);
        analysis.auto_update = this.shouldAutoUpdate(analysis);
        
        return analysis;
    }
    
    getUpdateType(current, target) {
        const currentVersion = semver.coerce(current);
        const targetVersion = semver.coerce(target);
        
        if (!currentVersion || !targetVersion) return 'unknown';
        
        if (semver.major(targetVersion) > semver.major(currentVersion)) {
            return 'major';
        } else if (semver.minor(targetVersion) > semver.minor(currentVersion)) {
            return 'minor';
        } else {
            return 'patch';
        }
    }
    
    async isSecurityUpdate(packageName, currentVersion, targetVersion) {
        try {
            // Check npm audit for security issues in current version
            const auditResult = execSync(`npm audit --json`, { encoding: 'utf8' });
            const audit = JSON.parse(auditResult);
            
            // Check if this package has security vulnerabilities
            const vulnerabilities = audit.vulnerabilities || {};
            return Object.keys(vulnerabilities).includes(packageName);
        } catch (error) {
            // If audit fails, assume it's not a security update
            return false;
        }
    }
    
    async hasBreakingChanges(packageName, currentVersion, targetVersion) {
        // For major version updates, assume breaking changes
        if (this.getUpdateType(currentVersion, targetVersion) === 'major') {
            return true;
        }
        
        // Check known breaking change patterns
        const breakingChangePatterns = [
            // Node.js version requirements
            { package: /node/, pattern: /engines.*node.*>.*\d+/ },
            // React version bumps
            { package: /react/, pattern: /peerDependencies.*react.*\^?\d+/ },
            // TypeScript version requirements
            { package: /typescript/, pattern: /typescript.*\^?\d+/ }
        ];
        
        return breakingChangePatterns.some(pattern => 
            pattern.package.test(packageName)
        );
    }
    
    getUpdateRecommendation(analysis) {
        // Security updates - immediate
        if (analysis.security_update) {
            return 'immediate';
        }
        
        // Framework updates - careful review
        if (this.updateStrategy.frameworks.packages.includes(analysis.package)) {
            return 'framework_review';
        }
        
        // Breaking changes - manual review
        if (analysis.breaking_changes) {
            return 'manual_review';
        }
        
        // Production dependencies with minor/major updates
        if (analysis.dependency_type === 'production' && 
            ['minor', 'major'].includes(analysis.update_type)) {
            return 'staging_test';
        }
        
        // Safe patch updates
        if (analysis.update_type === 'patch') {
            return 'auto_update';
        }
        
        return 'review';
    }
    
    assessRiskLevel(analysis) {
        let risk = 0;
        
        // Security updates reduce risk
        if (analysis.security_update) risk -= 2;
        
        // Update type risk
        switch (analysis.update_type) {
            case 'major': risk += 3; break;
            case 'minor': risk += 1; break;
            case 'patch': risk += 0; break;
        }
        
        // Breaking changes increase risk
        if (analysis.breaking_changes) risk += 2;
        
        // Framework updates are riskier
        if (this.updateStrategy.frameworks.packages.includes(analysis.package)) {
            risk += 1;
        }
        
        // Production vs development
        if (analysis.dependency_type === 'production') risk += 1;
        
        if (risk <= 0) return 'low';
        if (risk <= 2) return 'medium';
        return 'high';
    }
    
    shouldAutoUpdate(analysis) {
        // Never auto-update high-risk changes
        if (analysis.risk_level === 'high') return false;
        
        // Always auto-update security patches
        if (analysis.security_update && analysis.update_type === 'patch') return true;
        
        // Auto-update based on strategy
        const strategy = this.updateStrategy[analysis.dependency_type] || this.updateStrategy.production;
        
        return strategy.auto_update && 
               strategy.update_types.includes(analysis.update_type) &&
               !analysis.breaking_changes;
    }
    
    prioritizeUpdates(updatePlan) {
        return updatePlan.sort((a, b) => {
            // Security updates first
            if (a.security_update && !b.security_update) return -1;
            if (!a.security_update && b.security_update) return 1;
            
            // Then by risk level (low risk first for auto-updates)
            const riskOrder = { low: 0, medium: 1, high: 2 };
            const riskDiff = riskOrder[a.risk_level] - riskOrder[b.risk_level];
            if (riskDiff !== 0) return riskDiff;
            
            // Finally by update type (patch first)
            const typeOrder = { patch: 0, minor: 1, major: 2 };
            return typeOrder[a.update_type] - typeOrder[b.update_type];
        });
    }
    
    generateUpdateReport(updatePlan) {
        const autoUpdates = updatePlan.filter(u => u.auto_update);
        const manualUpdates = updatePlan.filter(u => !u.auto_update);
        
        return `# Dependency Update Plan

**Generated**: ${new Date().toISOString()}

## Summary
- **Total Updates Available**: ${updatePlan.length}
- **Auto-Updates**: ${autoUpdates.length}
- **Manual Review Required**: ${manualUpdates.length}
- **Security Updates**: ${updatePlan.filter(u => u.security_update).length}

## Auto-Updates (Safe to apply)
${autoUpdates.map(u => 
`- **${u.package}**: ${u.current_version} ‚Üí ${u.target_version} (${u.update_type})${u.security_update ? ' üîí' : ''}`
).join('\n')}

## Manual Review Required
${manualUpdates.map(u => 
`- **${u.package}**: ${u.current_version} ‚Üí ${u.target_version} (${u.update_type}, ${u.risk_level} risk)
  - **Reason**: ${u.recommendation}
  - **Breaking Changes**: ${u.breaking_changes ? 'Yes' : 'No'}
  - **Security Update**: ${u.security_update ? 'Yes' : 'No'}`
).join('\n')}

## Update Commands

### Auto-Updates
\`\`\`bash
${autoUpdates.map(u => `npm install ${u.package}@${u.target_version}`).join('\n')}
\`\`\`

### Security Updates (Immediate)
\`\`\`bash
${updatePlan.filter(u => u.security_update).map(u => 
`npm install ${u.package}@${u.target_version}  # Security fix`
).join('\n')}
\`\`\`
`;
    }
}

// Usage
async function main() {
    const updater = new SmartDependencyUpdater();
    const updatePlan = await updater.analyzeUpdates();
    const report = updater.generateUpdateReport(updatePlan);
    
    fs.writeFileSync('dependency-update-plan.md', report);
    console.log('Dependency update plan generated');
    
    // Apply auto-updates if requested
    if (process.argv.includes('--apply-auto-updates')) {
        const autoUpdates = updatePlan.filter(u => u.auto_update);
        console.log(`Applying ${autoUpdates.length} auto-updates...`);
        
        for (const update of autoUpdates) {
            try {
                execSync(`npm install ${update.package}@${update.target_version}`, 
                        { stdio: 'inherit' });
                console.log(`‚úÖ Updated ${update.package}`);
            } catch (error) {
                console.error(`‚ùå Failed to update ${update.package}:`, error.message);
            }
        }
    }
}

if (require.main === module) {
    main().catch(console.error);
}
```

---

## Navigation

| Previous | Next |
|----------|------|
| [‚Üê DAST Analysis](./dast-analysis.md) | [Tool Selection Guide ‚Üí](./tool-selection-guide.md) |

### Related Documents
- üîß [Implementation Guide](./implementation-guide.md)
- üèÜ [Best Practices](./best-practices.md)
- üìä [Comparison Analysis](./comparison-analysis.md)
- üí∞ [Cost Analysis](./cost-analysis.md)