# Best Practices: Production-Ready Terraform with AWS and Kubernetes

This document compiles best practices learned from analyzing 60+ production-ready open source projects, providing actionable guidance for implementing robust DevOps infrastructure.

## üìã Table of Contents

- [Infrastructure as Code Principles](#-infrastructure-as-code-principles)
- [Terraform Best Practices](#-terraform-best-practices)
- [AWS EKS Configuration](#-aws-eks-configuration)
- [Kubernetes Management](#-kubernetes-management)
- [Security Practices](#-security-practices)
- [GitOps Workflows](#-gitops-workflows)
- [Monitoring & Observability](#-monitoring--observability)
- [Cost Optimization](#-cost-optimization)
- [Team Collaboration](#-team-collaboration)

---

## üèóÔ∏è Infrastructure as Code Principles

### Directory Structure Best Practices
*Pattern from [terraform-aws-eks](https://github.com/terraform-aws-modules/terraform-aws-eks) and [eks-blueprints-for-terraform](https://github.com/aws-ia/terraform-aws-eks-blueprints)*

```
project-root/
‚îú‚îÄ‚îÄ environments/
‚îÇ   ‚îú‚îÄ‚îÄ dev/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.tf
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ variables.tf
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ terraform.tfvars
‚îÇ   ‚îú‚îÄ‚îÄ staging/
‚îÇ   ‚îî‚îÄ‚îÄ prod/
‚îú‚îÄ‚îÄ modules/
‚îÇ   ‚îú‚îÄ‚îÄ vpc/
‚îÇ   ‚îú‚îÄ‚îÄ eks/
‚îÇ   ‚îî‚îÄ‚îÄ monitoring/
‚îú‚îÄ‚îÄ shared/
‚îÇ   ‚îú‚îÄ‚îÄ data-sources.tf
‚îÇ   ‚îî‚îÄ‚îÄ locals.tf
‚îî‚îÄ‚îÄ .github/
    ‚îî‚îÄ‚îÄ workflows/
```

### Environment Separation
```hcl
# environments/dev/main.tf
module "infrastructure" {
  source = "../../modules/infrastructure"
  
  environment = "dev"
  
  # Environment-specific values
  node_instance_types = ["t3.medium"]
  node_desired_size   = 2
  monitoring_enabled  = false
}

# environments/prod/main.tf
module "infrastructure" {
  source = "../../modules/infrastructure"
  
  environment = "prod"
  
  # Production values
  node_instance_types = ["m5.large", "m5.xlarge"]
  node_desired_size   = 5
  monitoring_enabled  = true
  backup_enabled     = true
}
```

### Version Pinning Strategy
```hcl
terraform {
  required_version = ">= 1.5.0"
  
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"  # Allow patch updates
    }
    kubernetes = {
      source  = "hashicorp/kubernetes"
      version = "~> 2.20"
    }
    helm = {
      source  = "hashicorp/helm"
      version = "~> 2.10"
    }
  }
}
```

---

## üîß Terraform Best Practices

### State Management
*Lessons from [terraform-kubestack](https://github.com/kbst/terraform-kubestack)*

```hcl
# Backend configuration
terraform {
  backend "s3" {
    bucket         = "my-terraform-state-bucket"
    key            = "environments/prod/terraform.tfstate"
    region         = "us-west-2"
    encrypt        = true
    dynamodb_table = "terraform-locks"
    
    # Workspace support
    workspace_key_prefix = "environments"
  }
}

# S3 bucket setup for state
resource "aws_s3_bucket" "terraform_state" {
  bucket = "my-terraform-state-bucket"
}

resource "aws_s3_bucket_versioning" "terraform_state" {
  bucket = aws_s3_bucket.terraform_state.id
  versioning_configuration {
    status = "Enabled"
  }
}

resource "aws_s3_bucket_server_side_encryption_configuration" "terraform_state" {
  bucket = aws_s3_bucket.terraform_state.id

  rule {
    apply_server_side_encryption_by_default {
      sse_algorithm = "AES256"
    }
  }
}

# DynamoDB table for locking
resource "aws_dynamodb_table" "terraform_locks" {
  name           = "terraform-locks"
  billing_mode   = "PAY_PER_REQUEST"
  hash_key       = "LockID"

  attribute {
    name = "LockID"
    type = "S"
  }
}
```

### Module Design Patterns
```hcl
# modules/eks/main.tf
module "eks" {
  source = "terraform-aws-modules/eks/aws"
  
  # Required parameters
  cluster_name    = var.cluster_name
  cluster_version = var.cluster_version
  vpc_id          = var.vpc_id
  subnet_ids      = var.subnet_ids
  
  # Optional parameters with defaults
  cluster_endpoint_public_access  = var.enable_public_access
  cluster_endpoint_private_access = true
  
  # Conditional resources
  cluster_addons = var.enable_addons ? {
    coredns = {
      most_recent = true
    }
    kube-proxy = {
      most_recent = true
    }
    vpc-cni = {
      most_recent = true
    }
  } : {}
  
  tags = merge(var.common_tags, {
    Environment = var.environment
  })
}
```

### Variable Validation
```hcl
variable "cluster_version" {
  description = "Kubernetes version for the EKS cluster"
  type        = string
  
  validation {
    condition = can(regex("^1\\.(2[4-9]|[3-9][0-9])$", var.cluster_version))
    error_message = "Cluster version must be 1.24 or higher."
  }
}

variable "node_instance_types" {
  description = "List of instance types for EKS node groups"
  type        = list(string)
  
  validation {
    condition = length(var.node_instance_types) > 0
    error_message = "At least one instance type must be specified."
  }
}

variable "environment" {
  description = "Environment name"
  type        = string
  
  validation {
    condition     = contains(["dev", "staging", "prod"], var.environment)
    error_message = "Environment must be one of: dev, staging, prod."
  }
}
```

---

## ‚ò∏Ô∏è AWS EKS Configuration

### Cluster Security Configuration
*From [squareops/terraform-aws-eks](https://github.com/squareops/terraform-aws-eks)*

```hcl
module "eks" {
  source = "terraform-aws-modules/eks/aws"
  
  # Security best practices
  cluster_endpoint_public_access  = false  # Private clusters
  cluster_endpoint_private_access = true
  
  # Enable logging for security monitoring
  cluster_enabled_log_types = [
    "api",
    "audit",
    "authenticator",
    "controllerManager",
    "scheduler"
  ]
  
  # Encryption at rest
  cluster_encryption_config = [
    {
      provider_key_arn = aws_kms_key.eks.arn
      resources        = ["secrets"]
    }
  ]
  
  # Network access control
  cluster_security_group_additional_rules = {
    ingress_workstation_https = {
      description                = "Workstation access"
      protocol                   = "tcp"
      from_port                  = 443
      to_port                    = 443
      type                       = "ingress"
      source_security_group_id   = aws_security_group.workstation.id
    }
  }
}

# KMS key for EKS encryption
resource "aws_kms_key" "eks" {
  description = "EKS cluster encryption key"
  
  policy = jsonencode({
    Version = "2012-10-17"
    Statement = [
      {
        Effect = "Allow"
        Principal = {
          AWS = "arn:aws:iam::${data.aws_caller_identity.current.account_id}:root"
        }
        Action   = "kms:*"
        Resource = "*"
      }
    ]
  })
}
```

### Node Group Best Practices
```hcl
eks_managed_node_groups = {
  # Primary node group
  primary = {
    instance_types = ["m5.large"]
    capacity_type  = "ON_DEMAND"
    
    min_size     = 1
    max_size     = 10
    desired_size = 3
    
    # Use latest EKS optimized AMI
    ami_type = "AL2_x86_64"
    
    # Disk configuration
    disk_size = 50
    disk_type = "gp3"
    
    # Labels for workload placement
    labels = {
      role = "primary"
      "node.kubernetes.io/instance-type" = "m5.large"
    }
    
    # Taints for dedicated workloads
    taints = []
    
    # User data for custom setup
    pre_bootstrap_user_data = <<-EOT
      #!/bin/bash
      # Custom setup script
      yum update -y
      
      # Install monitoring agent
      amazon-cloudwatch-agent-ctl -a fetch-config -m ec2 -c ssm:cloudwatch-config
    EOT
  }
  
  # Spot instance node group for cost optimization
  spot = {
    instance_types = ["m5.large", "m5.xlarge", "m4.large"]
    capacity_type  = "SPOT"
    
    min_size     = 0
    max_size     = 20
    desired_size = 2
    
    labels = {
      role = "spot"
      "node.kubernetes.io/lifecycle" = "spot"
    }
    
    # Taint spot nodes
    taints = [
      {
        key    = "spot"
        value  = "true"
        effect = "NO_SCHEDULE"
      }
    ]
  }
}
```

### IRSA (IAM Roles for Service Accounts) Setup
```hcl
# Example: AWS Load Balancer Controller IRSA
module "aws_load_balancer_controller_irsa_role" {
  source = "terraform-aws-modules/iam/aws//modules/iam-role-for-service-accounts-eks"

  role_name = "aws-load-balancer-controller"

  attach_load_balancer_controller_policy = true

  oidc_providers = {
    ex = {
      provider_arn               = module.eks.oidc_provider_arn
      namespace_service_accounts = ["kube-system:aws-load-balancer-controller"]
    }
  }
}

# Service account annotation
resource "kubernetes_service_account" "aws_load_balancer_controller" {
  metadata {
    name      = "aws-load-balancer-controller"
    namespace = "kube-system"
    
    annotations = {
      "eks.amazonaws.com/role-arn" = module.aws_load_balancer_controller_irsa_role.iam_role_arn
    }
  }
}
```

---

## üîê Security Practices

### Network Security
*Inspired by [aws-k8s-platform-blueprint](https://github.com/mu-majid/aws-k8s-platform-blueprint)*

```hcl
# VPC with security-first design
module "vpc" {
  source = "terraform-aws-modules/vpc/aws"
  
  # Private subnets only for nodes
  private_subnets = ["10.0.1.0/24", "10.0.2.0/24", "10.0.3.0/24"]
  public_subnets  = ["10.0.101.0/24", "10.0.102.0/24", "10.0.103.0/24"]
  
  # Network ACLs for additional security
  manage_default_network_acl = true
  
  # Flow logs for monitoring
  enable_flow_log                      = true
  create_flow_log_cloudwatch_iam_role  = true
  create_flow_log_cloudwatch_log_group = true
  
  # DNS settings
  enable_dns_hostnames = true
  enable_dns_support   = true
}

# Security groups with least privilege
resource "aws_security_group" "node_group_sg" {
  name_prefix = "${var.cluster_name}-node-sg"
  vpc_id      = module.vpc.vpc_id

  # Only allow traffic from cluster security group
  ingress {
    from_port       = 0
    to_port         = 65535
    protocol        = "tcp"
    security_groups = [module.eks.cluster_security_group_id]
  }

  # HTTPS egress for pulling images and packages
  egress {
    from_port   = 443
    to_port     = 443
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }

  # DNS
  egress {
    from_port   = 53
    to_port     = 53
    protocol    = "udp"
    cidr_blocks = ["0.0.0.0/0"]
  }
}
```

### Pod Security Standards
```yaml
# pod-security-policy.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: secure-namespace
  labels:
    pod-security.kubernetes.io/enforce: restricted
    pod-security.kubernetes.io/audit: restricted
    pod-security.kubernetes.io/warn: restricted
```

### Network Policies
```yaml
# network-policy.yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: deny-all-ingress
  namespace: production
spec:
  podSelector: {}
  policyTypes:
  - Ingress
  - Egress
  egress:
  # Allow DNS
  - ports:
    - protocol: UDP
      port: 53
  # Allow HTTPS
  - ports:
    - protocol: TCP
      port: 443
```

---

## üîÑ GitOps Workflows

### FluxCD Integration
*Based on [tofu-controller](https://github.com/flux-iac/tofu-controller) and [k8s-gitops](https://github.com/xunholy/k8s-gitops)*

```hcl
# GitOps repository setup
resource "helm_release" "flux2" {
  name             = "flux2"
  repository       = "https://fluxcd-community.github.io/helm-charts"
  chart            = "flux2"
  namespace        = "flux-system"
  create_namespace = true

  values = [
    yamlencode({
      cli = {
        image = "fluxcd/flux-cli:v0.41.2"
      }
      controllers = {
        source = {
          create = true
        }
        kustomize = {
          create = true
        }
        helm = {
          create = true
        }
        notification = {
          create = true
        }
      }
    })
  ]
}

# Terraform Controller for Infrastructure GitOps
resource "helm_release" "tofu_controller" {
  name       = "tofu-controller"
  repository = "https://flux-iac.github.io/tofu-controller/"
  chart      = "tofu-controller"
  namespace  = "flux-system"

  values = [
    yamlencode({
      replicaCount = 2
      
      # Resource limits
      resources = {
        limits = {
          cpu    = "1000m"
          memory = "1Gi"
        }
        requests = {
          cpu    = "100m"
          memory = "64Mi"
        }
      }
      
      # Security context
      securityContext = {
        allowPrivilegeEscalation = false
        readOnlyRootFilesystem   = true
        runAsNonRoot             = true
        capabilities = {
          drop = ["ALL"]
        }
      }
    })
  ]

  depends_on = [helm_release.flux2]
}
```

### GitOps Directory Structure
```
gitops-repo/
‚îú‚îÄ‚îÄ clusters/
‚îÇ   ‚îú‚îÄ‚îÄ dev/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ infrastructure/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ terraform-source.yaml
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ applications/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ kustomization.yaml
‚îÇ   ‚îî‚îÄ‚îÄ prod/
‚îú‚îÄ‚îÄ infrastructure/
‚îÇ   ‚îú‚îÄ‚îÄ terraform/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ vpc/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ eks/
‚îÇ   ‚îî‚îÄ‚îÄ crossplane/
‚îî‚îÄ‚îÄ applications/
    ‚îú‚îÄ‚îÄ base/
    ‚îî‚îÄ‚îÄ overlays/
```

### Terraform Source Configuration
```yaml
# clusters/prod/infrastructure/terraform-source.yaml
apiVersion: source.toolkit.fluxcd.io/v1beta2
kind: GitRepository
metadata:
  name: infrastructure-source
  namespace: flux-system
spec:
  interval: 5m
  url: https://github.com/your-org/infrastructure
  ref:
    branch: main
  secretRef:
    name: git-credentials
---
apiVersion: infra.contrib.fluxcd.io/v1alpha1
kind: Terraform
metadata:
  name: eks-cluster
  namespace: flux-system
spec:
  interval: 10m
  path: "./terraform/eks"
  sourceRef:
    kind: GitRepository
    name: infrastructure-source
  vars:
    - name: cluster_name
      value: "prod-cluster"
    - name: environment
      value: "prod"
  writeOutputsToSecret:
    name: eks-outputs
```

---

## üìä Monitoring & Observability

### Prometheus Stack Setup
*From [terraform-kubernetes-monitoring-prometheus](https://github.com/mateothegreat/terraform-kubernetes-monitoring-prometheus)*

```hcl
resource "helm_release" "kube_prometheus_stack" {
  name             = "kube-prometheus-stack"
  repository       = "https://prometheus-community.github.io/helm-charts"
  chart            = "kube-prometheus-stack"
  namespace        = "monitoring"
  create_namespace = true

  values = [
    yamlencode({
      # Prometheus configuration
      prometheus = {
        prometheusSpec = {
          # Retention settings
          retention = "30d"
          retentionSize = "50GB"
          
          # Storage configuration
          storageSpec = {
            volumeClaimTemplate = {
              spec = {
                storageClassName = "gp3"
                accessModes      = ["ReadWriteOnce"]
                resources = {
                  requests = {
                    storage = "100Gi"
                  }
                }
              }
            }
          }
          
          # Resource limits
          resources = {
            limits = {
              cpu    = "2000m"
              memory = "4Gi"
            }
            requests = {
              cpu    = "1000m"
              memory = "2Gi"
            }
          }
          
          # Security context
          securityContext = {
            runAsNonRoot = true
            runAsUser    = 65534
            fsGroup      = 65534
          }
        }
      }
      
      # Grafana configuration
      grafana = {
        enabled = true
        
        # Admin credentials
        adminPassword = random_password.grafana_admin.result
        
        # Persistence
        persistence = {
          enabled          = true
          size             = "10Gi"
          storageClassName = "gp3"
        }
        
        # Datasources
        datasources = {
          "datasources.yaml" = {
            apiVersion = 1
            datasources = [
              {
                name      = "Prometheus"
                type      = "prometheus"
                url       = "http://kube-prometheus-stack-prometheus:9090"
                isDefault = true
              }
            ]
          }
        }
        
        # Dashboards
        dashboardProviders = {
          "dashboardproviders.yaml" = {
            apiVersion = 1
            providers = [
              {
                name    = "default"
                orgId   = 1
                folder  = ""
                type    = "file"
                options = {
                  path = "/var/lib/grafana/dashboards/default"
                }
              }
            ]
          }
        }
      }
      
      # AlertManager configuration
      alertmanager = {
        alertmanagerSpec = {
          storage = {
            volumeClaimTemplate = {
              spec = {
                storageClassName = "gp3"
                accessModes      = ["ReadWriteOnce"]
                resources = {
                  requests = {
                    storage = "10Gi"
                  }
                }
              }
            }
          }
        }
        
        config = {
          global = {
            slack_api_url = var.slack_webhook_url
          }
          route = {
            group_by        = ["alertname"]
            group_wait      = "10s"
            group_interval  = "10s"
            repeat_interval = "1h"
            receiver        = "web.hook"
          }
          receivers = [
            {
              name = "web.hook"
              slack_configs = [
                {
                  channel  = "#alerts"
                  title    = "{{ range .Alerts }}{{ .Annotations.summary }}{{ end }}"
                  text     = "{{ range .Alerts }}{{ .Annotations.description }}{{ end }}"
                }
              ]
            }
          ]
        }
      }
    })
  ]
}

# Generate random password for Grafana
resource "random_password" "grafana_admin" {
  length  = 16
  special = true
}

# Store password in AWS Secrets Manager
resource "aws_secretsmanager_secret" "grafana_admin" {
  name = "${var.cluster_name}-grafana-admin"
}

resource "aws_secretsmanager_secret_version" "grafana_admin" {
  secret_id     = aws_secretsmanager_secret.grafana_admin.id
  secret_string = random_password.grafana_admin.result
}
```

### Log Aggregation
```hcl
# EFK Stack (Elasticsearch, Fluent Bit, Kibana)
resource "helm_release" "fluent_bit" {
  name             = "fluent-bit"
  repository       = "https://fluent.github.io/helm-charts"
  chart            = "fluent-bit"
  namespace        = "logging"
  create_namespace = true

  values = [
    yamlencode({
      config = {
        outputs = |
          [OUTPUT]
              Name cloudwatch_logs
              Match *
              region ${var.aws_region}
              log_group_name /aws/eks/${var.cluster_name}/application
              auto_create_group true
      }
      
      # Resource limits
      resources = {
        limits = {
          cpu    = "200m"
          memory = "200Mi"
        }
        requests = {
          cpu    = "100m"
          memory = "100Mi"
        }
      }
      
      # Security context
      securityContext = {
        runAsNonRoot = true
        runAsUser    = 65534
      }
    })
  ]
}
```

---

## üí∞ Cost Optimization

### Resource Right-Sizing
*Patterns from [aws-k8s-platform-blueprint](https://github.com/mu-majid/aws-k8s-platform-blueprint)*

```hcl
# Mixed instance types for cost optimization
eks_managed_node_groups = {
  # On-demand for critical workloads
  on_demand = {
    instance_types = ["m5.large"]
    capacity_type  = "ON_DEMAND"
    
    min_size     = 1
    max_size     = 5
    desired_size = 2
    
    labels = {
      "node.kubernetes.io/lifecycle" = "on-demand"
    }
  }
  
  # Spot instances for flexible workloads
  spot = {
    instance_types = ["m5.large", "m5.xlarge", "m4.large", "c5.large"]
    capacity_type  = "SPOT"
    
    min_size     = 0
    max_size     = 20
    desired_size = 3
    
    labels = {
      "node.kubernetes.io/lifecycle" = "spot"
    }
    
    taints = [
      {
        key    = "spot"
        value  = "true"
        effect = "NO_SCHEDULE"
      }
    ]
  }
}
```

### Cluster Autoscaler Configuration
```yaml
# cluster-autoscaler-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: cluster-autoscaler-status
  namespace: kube-system
data:
  # Scale down settings for cost optimization
  scale-down-delay-after-add: "10m"
  scale-down-unneeded-time: "10m"
  skip-nodes-with-local-storage: "false"
  skip-nodes-with-system-pods: "false"
```

### Vertical Pod Autoscaler
```hcl
resource "helm_release" "vpa" {
  name             = "vpa"
  repository       = "https://charts.fairwinds.com/stable"
  chart            = "vpa"
  namespace        = "vpa"
  create_namespace = true

  values = [
    yamlencode({
      # Enable all VPA components
      recommender = {
        enabled = true
      }
      updater = {
        enabled = true
      }
      admissionController = {
        enabled = true
      }
    })
  ]
}
```

---

## üë• Team Collaboration

### Multi-Environment Strategy
*From [terraform-kubestack](https://github.com/kbst/terraform-kubestack)*

```hcl
# Terragrunt configuration for environment management
# terragrunt.hcl
terraform {
  source = "../../../modules/infrastructure"
}

include {
  path = find_in_parent_folders()
}

inputs = {
  environment = "dev"
  
  # Environment-specific overrides
  cluster_version     = "1.27"
  node_instance_types = ["t3.medium"]
  node_desired_size   = 2
  
  # Feature flags
  enable_monitoring = false
  enable_logging    = true
  enable_backups    = false
  
  # Cost optimization for dev
  spot_instances_enabled = true
}
```

### Code Review Process
```yaml
# .github/workflows/terraform-pr.yml
name: Terraform PR Validation
on:
  pull_request:
    paths:
    - 'terraform/**'
    - 'environments/**'

jobs:
  validate:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    
    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v2
      with:
        terraform_version: 1.5.0
    
    - name: Terraform Format Check
      run: terraform fmt -check -recursive
      
    - name: Terraform Validate
      run: |
        find . -name "*.tf" -exec dirname {} \; | sort -u | while read dir; do
          echo "Validating $dir"
          (cd "$dir" && terraform init -backend=false && terraform validate)
        done
    
    - name: Security Scan
      uses: aquasecurity/trivy-action@master
      with:
        scan-type: 'config'
        format: 'sarif'
        output: 'trivy-results.sarif'
    
    - name: Plan Changes
      run: |
        cd environments/dev
        terraform init
        terraform plan -out=plan.out
```

### Documentation Standards
```markdown
# Module: EKS Cluster

## Description
This module creates a production-ready EKS cluster with the following features:
- Private API endpoint
- Managed node groups with mixed instance types
- Comprehensive security configurations
- Integrated monitoring and logging

## Usage
```hcl
module "eks_cluster" {
  source = "./modules/eks"
  
  cluster_name = "my-cluster"
  environment  = "prod"
  vpc_id       = module.vpc.vpc_id
  subnet_ids   = module.vpc.private_subnets
}
```

## Requirements
| Name | Version |
|------|---------|
| terraform | >= 1.5.0 |
| aws | ~> 5.0 |
| kubernetes | ~> 2.20 |

## Inputs
| Name | Description | Type | Default | Required |
|------|-------------|------|---------|:--------:|
| cluster_name | Name of the EKS cluster | `string` | n/a | yes |
| environment | Environment name | `string` | n/a | yes |

## Outputs
| Name | Description |
|------|-------------|
| cluster_endpoint | EKS cluster endpoint |
| cluster_arn | EKS cluster ARN |
```

---

## üîç Quality Gates

### Pre-commit Hooks
```yaml
# .pre-commit-config.yaml
repos:
- repo: https://github.com/antonbabenko/pre-commit-terraform
  rev: v1.81.0
  hooks:
  - id: terraform_fmt
  - id: terraform_validate
  - id: terraform_docs
  - id: terraform_tflint
  - id: terraform_tfsec

- repo: https://github.com/aquasecurity/trivy
  rev: v0.43.1
  hooks:
  - id: trivy-config
```

### Testing Strategy
```hcl
# tests/eks_test.go
package test

import (
    "testing"
    "github.com/gruntwork-io/terratest/modules/terraform"
    "github.com/stretchr/testify/assert"
)

func TestEKSCluster(t *testing.T) {
    terraformOptions := &terraform.Options{
        TerraformDir: "../examples/complete",
        Vars: map[string]interface{}{
            "cluster_name": "test-cluster",
            "environment":  "test",
        },
    }

    defer terraform.Destroy(t, terraformOptions)
    terraform.InitAndApply(t, terraformOptions)

    clusterName := terraform.Output(t, terraformOptions, "cluster_name")
    assert.Equal(t, "test-cluster", clusterName)
}
```

---

## üéØ Summary Checklist

### Infrastructure Setup ‚úÖ
- [ ] VPC with proper subnet design
- [ ] EKS cluster with security configurations
- [ ] IAM roles and policies following least privilege
- [ ] Encryption at rest and in transit
- [ ] Network policies and security groups

### Operations ‚úÖ
- [ ] GitOps workflow implementation
- [ ] Monitoring and alerting setup
- [ ] Log aggregation and retention
- [ ] Backup and disaster recovery
- [ ] Cost optimization measures

### Team Practices ‚úÖ
- [ ] Code review process
- [ ] Automated testing
- [ ] Security scanning
- [ ] Documentation standards
- [ ] Environment promotion workflow

---

## Navigation
‚Üê [Implementation Guide](./implementation-guide.md) | ‚Üí [Comparison Analysis](./comparison-analysis.md) | ‚Üë [README](./README.md)